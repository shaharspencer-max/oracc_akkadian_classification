1. https://gemini.google.com/app/d5a0904bfabaa5fd


Methodological Report: Zero-Shot Geolocation of Akkadian Texts via Large Language Models1. ObjectiveThe primary objective was to establish a rigorous baseline for predicting the geographical provenance of 2nd and 1st Millennium BCE Akkadian texts using an off-the-shelf Large Language Model (gemini-2.5-flash). The goal was to assess the model's ability to utilize lexical, morphological, and orthographic variation for geolocation, rather than relying on simple entity recognition (NER) or memorized historical facts.2. Data Pre-processing & Masking StrategyTo ensure the model performed genuine linguistic analysis rather than "entity lookup," a strict masking protocol was developed. We categorized entities into "Spoilers" (direct labels of location) and "Features" (cultural signals).2.1 The "Gentilic Leak" & The "Crowd" HypothesisA critical methodological decision was distinguishing between Ethnic Names (EN) and Personal Names (PN).Decision: We masked Ethnic Names (EN) because they often function as "Gentilics" (e.g., Aššurāyu = "The Assyrian"), which act as direct labels for the city of origin.Decision: We preserved Personal Names (PN). Following Eisenstein et al. (2010) regarding latent variables in geographic lexical variation, we hypothesized that the distribution of names (Onomastics) serves as a valid cultural fingerprint (e.g., Hurrian names indicating the Nuzi cluster) without explicitly revealing the city name.2.2 Final Baseline Masking ProtocolThe following Named Entity tags were masked with generic tokens (e.g., [GN], [RN]) to prevent data leakage:Geographical Markers: GN (Geo Name), SN (City), TN (Temple), WN (River), QN (Quarter).Political/Religious Proxies: RN / KN (Kings, who are chronological/spatial anchors), DN (Divine Names, as Patron Deities effectively label cities).Explicit Labels: EN (Ethnic Names/Gentilics).Unmasked Features: PN (Personal Names) and LN (Family Names) were retained to provide onomastic signals for clustering.3. Prompt Engineering & System ConstraintsInitial experiments using open-ended prompting resulted in significant "Gravity Well" bias, where provincial texts were consistently misclassified as major capitals (e.g., Tell Rimah $\rightarrow$ Assur).To correct this, a Constrained Candidate System was implemented:Regional Grouping: The model was provided with a closed list of candidates grouped by region (e.g., Assyria, Babylonia, Levant - Coastal, Levant - Inland). This reduced cross-regional hallucinations (e.g., confusing Ugarit with Nuzi).Base Rate Correction: Specific heuristics were encoded to counter training data bias. For example, in the Amarna corpus, the model was instructed to weigh Byblos higher than Jerusalem absent specific "Inland" keywords.Chain-of-Thought (CoT): The model was required to output a "Philological Analysis" regarding dialect and morphology before generating the final classification tag.4. Experimental Results & Error Analysis4.1 The "Capital City" Bias (Neo-Assyria)The confusion matrix revealed a distinct "Neo-Assyrian Gravity Well."Observation: Texts from Nimrud (Kalhu) were frequently misclassified as Nineveh.Analysis: Without Royal Names (RN) to distinguish the era (e.g., Ashurnasirpal II vs. Ashurbanipal), the dialect of the Neo-Assyrian chancellery is effectively identical across these capitals. The model defaulted to Nineveh due to its higher representation in the training corpus.Implication: The model successfully identified the "Assyrian Cluster" but struggled with fine-grained city distinction within the core heartland.4.2 The "Library" Effect (Babylonia vs. Assyria)Observation: Standard Babylonian literary texts found at Nineveh were often predicted as Babylon.Analysis: This represents a correct linguistic classification but an incorrect archaeological one. The model identified the Standard Babylonian dialect correctly, ignoring the physical find-spot (the Library of Ashurbanipal).Success: The model achieved 100% accuracy on true Babylonian texts, proving it successfully distinguishes the Southern dialect from the Northern (Assyrian) dialect solely on grammatical features.4.3 The Amarna ImprovementInitial runs showed a massive bias toward "Biblical" cities (Jerusalem, Lachish). After implementing "Coastal vs. Inland" candidate splitting and base-rate constraints, the model began correctly identifying Phoenician coastal origins (Byblos, Tyre) based on maritime context and formulaic distinctiveness.5. Conclusion & MetricsThe "Baseline" performance demonstrates that gemini-2.5-flash can act as a Dialect Classifier but requires careful constraints to act as a Provenance Predictor.Future Evaluation Metrics (per Advisory Board recommendations):Geodesic Error: Measuring Haversine distance between Predicted and True coordinates to penalize "near misses" (e.g., Nimrud $\rightarrow$ Nineveh) less than "far misses."Cluster Accuracy: Evaluating performance based on 100km/150km geographic clusters, where identifying the correct cultural zone (e.g., Middle Euphrates) is weighted positively even if the specific city is incorrect.





2. https://gemini.google.com/app/489c38b368b5c45b